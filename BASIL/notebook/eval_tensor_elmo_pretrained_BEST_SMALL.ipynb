{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/can/Documents/thai_nlp_research/BASIL/notebook\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "mypath = Path().absolute()\n",
    "print(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/can/Documents/thai_nlp_research/BASIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/can/Documents/thai_nlp_research/BASIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from basil.preprocessing.prep_best_corpus import Best2010NECTEC, BestSyllable2010NECTEC\n",
    "from basil.preprocessing.prep_pytorch import PytorchPrepWordLevel\n",
    "from basil.models.multitasks.elmo_lstm_pretrained import LSTMTagger\n",
    "from basil.evaluation.stress_test import StressEval\n",
    "from basil.select_device import device\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing BEST2010 corpus\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "best2010  = Best2010NECTEC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0.9281115573228177 0.7532111337406654\n",
      "10 0.8919554580583898 0.711456450032433\n",
      "20 0.8546407728576608 0.6723905345399358\n",
      "30 0.8178480990398481 0.6311775079212605\n",
      "40 0.7807506143748325 0.5839923982165047\n",
      "50 0.7427379416309654 0.5393385526746644\n",
      "60 0.7040051699466079 0.49542308214323416\n",
      "70 0.665982318314305 0.43980659014722007\n",
      "80 0.6279691381091597 0.39568964168973547\n",
      "90 0.588894213226534 0.35490989918234506\n",
      "100 0.5499080072187406 0.311186059584036\n"
     ]
    }
   ],
   "source": [
    "stress_eval  = StressEval(LSTMTagger, \"model_elmo_pretrained_small.p\",best2010 )\n",
    "stress_eval.f1_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_eval.f1_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "stress_eval.f1_summary()\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0.9428369205880283 0.8045219916120013\n",
      "10 0.9069855365542708 0.7625765782974716\n",
      "20 0.8697680143842511 0.7235669498241272\n",
      "30 0.8336106598906666 0.6841770451943058\n",
      "40 0.7959370287819438 0.6391562179866391\n",
      "50 0.7582345842647729 0.5940628945591214\n",
      "60 0.7206868582959108 0.5538507462686567\n",
      "70 0.6830528183023143 0.5040878584502746\n",
      "80 0.6450857039860376 0.45811668658523336\n",
      "90 0.6070172507781314 0.410934299669135\n",
      "100 0.5681980041324131 0.3630536688032144\n"
     ]
    }
   ],
   "source": [
    "cap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp)",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
