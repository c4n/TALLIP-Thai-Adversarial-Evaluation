{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/datamind/can/BASIL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "os.chdir(base_dir)\n",
    "sys.path.append(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from basil.select_device import device\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basil.preprocessing.prep_pytorch import PytorchPrepWordLevel\n",
    "from basil.preprocessing.prep_pytorch_syllable import PytorchPrepWordLevelWithSyllable\n",
    "from basil.evaluation.noise import NoiseGenerator\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import pickle\n",
    "from basil.select_device import device\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datamind/can/BASIL/basil/preprocessing/prep_best_corpus.py:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(ymlfile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing BEST2010 corpus\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from basil.preprocessing.prep_best_corpus import Best2010NECTEC\n",
    "from basil.preprocessing.prep_pytorch import PytorchPrepWordLevel\n",
    "\n",
    "best2010  = Best2010NECTEC()\n",
    "prep_torch = PytorchPrepWordLevel(best2010.train_data, best2010.val_data, best2010.test_data)\n",
    "y_true_pos = [prep_torch.pos_to_index[word] for text in prep_torch.pos_test for word in text]\n",
    "y_true_ner = [prep_torch.ner_to_index[word] for text in prep_torch.ner_test for word in text]\n",
    "stress_best = pickle.load( open( base_dir+\"stress_best2010.p\", \"rb\" ) )\n",
    "error10 = [item for sublist in stress_best.error10   for item in sublist] \n",
    "error20 = [item for sublist in stress_best.error20   for item in sublist] \n",
    "error30 = [item for sublist in stress_best.error30   for item in sublist] \n",
    "error40 = [item for sublist in stress_best.error40   for item in sublist] \n",
    "error50 = [item for sublist in stress_best.error50   for item in sublist] \n",
    "error60 = [item for sublist in stress_best.error60   for item in sublist] \n",
    "error70 = [item for sublist in stress_best.error70   for item in sublist] \n",
    "error80 = [item for sublist in stress_best.error80   for item in sublist] \n",
    "error90 = [item for sublist in stress_best.error90   for item in sublist] \n",
    "error100 = [item for sublist in stress_best.error100   for item in sublist] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basil.models.multitasks.wordlvl_lstm import LSTMTagger\n",
    "from basil.models.multitasks.elmo_lstm_pretrained import LSTMTagger as ELMO\n",
    "from basil.models.multitasks.BiLSTM_B import LSTMTagger as BiLSTM_B\n",
    "from basil.models.multitasks.BILSTM_UBC import LSTMTagger as BiLSTM_UBC\n",
    "from basil.models.multitasks.BiLSTM_BA import LSTMTagger as BiLSTM_BA\n",
    "from basil.models.multitasks.BiLSTM_BCA import LSTMTagger as BiLSTM_BCA\n",
    "from basil.models.multitasks.BiLSTM_BCAD import LSTMTagger as BiLSTM_BCAD\n",
    "CHAR_EMBEDDING_DIM = 100\n",
    "WORD_EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = LSTMTagger(WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model.load_state_dict(torch.load(\"weights/model_bilstm_baseline_seed1.p\"))\n",
    "prep_torch = PytorchPrepWordLevel(best2010.train_data, best2010.val_data, best2010.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['วัน','นี้','ฉัน','รู้สึก','เมื่อย','มาก']\n",
    "cases = [['วัน','นี้','ฉัน','รู้สึก','เมือย','มาก'],\n",
    "         ['วัน','นี้','ฉัน','รูสึก','เมือย','มาก'],\n",
    "        ['วั','นี','ฉั','รู้สึก','เมือย','มา'],\n",
    "        ['วั','นี','ฉั','รูสึก','เมือย','มา']]\n",
    "w_in = prep_torch.prepare_sequence_test_word(text)\n",
    "pred_pos, pred_ner = model(w_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for pos in pred_pos:\n",
    "    pos=pos.data.tolist()\n",
    "    pos = pos.index(max(pos))\n",
    "    pos = prep_torch.index_to_pos[pos]\n",
    "    ans.append(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* วัน - NN - common nouns\n",
    "* นี้ - DDEM - Demonstrative Determiner -\n",
    "* ฉัน - PPER (Personal Pronoun)\n",
    "* รู้สึก - VV - main verbs in clauses verb form\n",
    "* เมื่อย - VV - serial verbs\n",
    "* มาก - ADV - adverbs modifying Verb/Adj/other adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN', 'NR', 'PU', 'NR', 'VV', 'VV']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = LSTMTagger(WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_base.load_state_dict(torch.load(\"weights/model_bilstm_baseline_seed1.p\"))\n",
    "\n",
    "model_elmo_pretrained_small_seed1 = ELMO(CHAR_EMBEDDING_DIM,WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_elmo_pretrained_small_seed1.load_state_dict(torch.load(\"weights/model_elmo_pretrained_small_seed1.p\"))\n",
    "\n",
    "model_bilstm_UNK_seed1 = LSTMTagger(WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_bilstm_UNK_seed1.load_state_dict(torch.load(\"weights/model_bilstm_UNK_seed1.p\"))\n",
    "\n",
    "\n",
    "model_bilstm_backoff_unk_seed1 = BiLSTM_B(CHAR_EMBEDDING_DIM,WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_bilstm_backoff_unk_seed1.load_state_dict(torch.load(\"weights/model_bilstm_backoff_unk_seed1.p\"))\n",
    "\n",
    "model_bilstm_BA_seed1 = BiLSTM_BA(CHAR_EMBEDDING_DIM,WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_bilstm_BA_seed1.load_state_dict(torch.load(\"weights/model_bilstm_BA_seed1.p\"))\n",
    "\n",
    "model_bilstm_UBC_seed1 =  BiLSTM_UBC(CHAR_EMBEDDING_DIM,WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),prep_torch.prefix_size,\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_bilstm_UBC_seed1.load_state_dict(torch.load(\"weights/model_bilstm_UBC_seed1.p\"))\n",
    "\n",
    "\n",
    "model_bilstm_BCAD_clp_seed1 = BiLSTM_BCAD(CHAR_EMBEDDING_DIM,WORD_EMBEDDING_DIM,HIDDEN_DIM,\\\n",
    "                           len(prep_torch.char_to_index),len(prep_torch.word_to_index),prep_torch.prefix_size,\\\n",
    "                           len(prep_torch.pos_to_index),len(prep_torch.ner_to_index)).to(device)\n",
    "model_bilstm_BCAD_clp_seed1.load_state_dict(torch.load(\"weights/model_bilstm_BCAD_clp_seed1.p\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-BaseLine\n",
      "['วัน', 'นี้', 'ฉัน', 'รู้สึก', 'เมือย', 'มาก']\n",
      "NN & DDEM & PPER & VV & VA & ADV\n",
      "['วัน', 'นี้', 'ฉัน', 'รูสึก', 'เมือย', 'มาก']\n",
      "NN & DDEM & P & VV & ADV & ADV\n",
      "['วั', 'นี', 'ฉั', 'รู้สึก', 'เมือย', 'มา']\n",
      "NR & NN & NR & VV & VV & VV\n",
      "['วั', 'นี', 'ฉั', 'รูสึก', 'เมือย', 'มา']\n",
      "FWN & NN & NR & NR & VV & VV\n"
     ]
    }
   ],
   "source": [
    "print(\"BiLSTM-BaseLine\")\n",
    "for case in cases:\n",
    "    w_in = prep_torch.prepare_sequence_test_word(case)   \n",
    "    pred_pos, pred_ner = model_base(w_in)\n",
    "    ans = []\n",
    "    for pos in pred_pos:\n",
    "        pos=pos.data.tolist()\n",
    "        pos = pos.index(max(pos))\n",
    "        pos = prep_torch.index_to_pos[pos]\n",
    "        ans.append(pos)\n",
    "    print(case)    \n",
    "    print(\" & \".join(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* วัน - NN - common nouns\n",
    "* นี้ - DDEM - Demonstrative Determiner -\n",
    "* ฉัน - PPER (Personal Pronoun)\n",
    "* รู้สึก - VV - main verbs in clauses verb form\n",
    "* เมื่อย - VV - serial verbs\n",
    "* มาก - ADV - adverbs modifying Verb/Adj/other adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-UNK\n",
      "['วัน', 'นี้', 'ฉัน', 'รู้สึก', 'เมือย', 'มาก']\n",
      "NN & DDEM & PPER & VV & FXAV & JJA\n",
      "['วัน', 'นี้', 'ฉัน', 'รูสึก', 'เมือย', 'มาก']\n",
      "NN & DDEM & PPER & VV & FXAV & JJA\n",
      "['วั', 'นี', 'ฉั', 'รู้สึก', 'เมือย', 'มา']\n",
      "NN & NR & PU & VV & VV & VV\n",
      "['วั', 'นี', 'ฉั', 'รูสึก', 'เมือย', 'มา']\n",
      "NN & NR & PU & NR & VV & VV\n"
     ]
    }
   ],
   "source": [
    "print(\"BiLSTM-UNK\")\n",
    "for case in cases:\n",
    "    w_in = prep_torch.prepare_sequence_test_word(case)   \n",
    "    pred_pos, pred_ner = model_bilstm_UNK_seed1(w_in)\n",
    "    ans = []\n",
    "    for pos in pred_pos:\n",
    "        pos=pos.data.tolist()\n",
    "        pos = pos.index(max(pos))\n",
    "        pos = prep_torch.index_to_pos[pos]\n",
    "        ans.append(pos)\n",
    "    print(case)    \n",
    "    print(\" & \".join(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMO\n",
      "['วัน', 'นี้', 'ฉัน', 'รู้สึก', 'เมือย', 'มาก']\n",
      "NN & DDEM & PPER & VV & VV & ADV\n",
      "['วัน', 'นี้', 'ฉัน', 'รูสึก', 'เมือย', 'มาก']\n",
      "NN & DDEM & PPER & VV & ADV & ADV\n",
      "['วั', 'นี', 'ฉั', 'รู้สึก', 'เมือย', 'มา']\n",
      "NN & DDEM & PPER & VV & ADV & ADV\n",
      "['วั', 'นี', 'ฉั', 'รูสึก', 'เมือย', 'มา']\n",
      "NN & DDEM & PPER & VV & VV & ADV\n"
     ]
    }
   ],
   "source": [
    "print(\"ELMO\")\n",
    "for case in cases: \n",
    "    w_in = batch_to_ids([text]).to(device)\n",
    "    pred_pos, pred_ner = model_elmo_pretrained_small_seed1(w_in)\n",
    "    ans = []\n",
    "    for pos in pred_pos:\n",
    "        pos=pos.data.tolist()\n",
    "        pos = pos.index(max(pos))\n",
    "        pos = prep_torch.index_to_pos[pos]\n",
    "        ans.append(pos)\n",
    "    print(case)    \n",
    "    print(\" & \".join(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCAD-clp\n",
      "['วัน', 'นี้', 'ฉัน', 'รู้สึก', 'เมือย', 'มาก']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n",
      "['วัน', 'นี้', 'ฉัน', 'รูสึก', 'เมือย', 'มาก']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n",
      "['วั', 'นี', 'ฉั', 'รู้สึก', 'เมือย', 'มา']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n",
      "['วั', 'นี', 'ฉั', 'รูสึก', 'เมือย', 'มา']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n"
     ]
    }
   ],
   "source": [
    "print(\"BCAD-clp\")\n",
    "for case in cases: \n",
    "    wtest_in = prep_torch.prepare_sequence_test_word(text)\n",
    "    ctest_in = [prep_torch.prepare_sequence_test_char(word) for word in text]\n",
    "    ptest_in = prep_torch.prepare_sequence_feat_prefix(text)  \n",
    "    pred_pos, pred_ner = model_bilstm_BCAD_clp_seed1(wtest_in,ctest_in,ptest_in)\n",
    "    ans = []\n",
    "    for pos in pred_pos:\n",
    "        pos=pos.data.tolist()\n",
    "        pos = pos.index(max(pos))\n",
    "        pos = prep_torch.index_to_pos[pos]\n",
    "        ans.append(pos)\n",
    "    print(case)    \n",
    "    print(ans)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC\n",
      "['วัน', 'นี้', 'ฉัน', 'รู้สึก', 'เมือย', 'มาก']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n",
      "['วัน', 'นี้', 'ฉัน', 'รูสึก', 'เมือย', 'มาก']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n",
      "['วั', 'นี', 'ฉั', 'รู้สึก', 'เมือย', 'มา']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n",
      "['วั', 'นี', 'ฉั', 'รูสึก', 'เมือย', 'มา']\n",
      "['NN', 'DDEM', 'PPER', 'VV', 'VV', 'ADV']\n"
     ]
    }
   ],
   "source": [
    "print(\"UBC\")\n",
    "for case in cases: \n",
    "    wtest_in = prep_torch.prepare_sequence_test_word(text)\n",
    "    ctest_in = [prep_torch.prepare_sequence_test_char(word) for word in text]\n",
    "    ptest_in = prep_torch.prepare_sequence_feat_prefix(text)  \n",
    "    pred_pos, pred_ner = model_bilstm_UBC_seed1(wtest_in,ctest_in,ptest_in)\n",
    "    ans = []\n",
    "    for pos in pred_pos:\n",
    "        pos=pos.data.tolist()\n",
    "        pos = pos.index(max(pos))\n",
    "        pos = prep_torch.index_to_pos[pos]\n",
    "        ans.append(pos)\n",
    "    print(case)    \n",
    "    print(ans)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "วัน & นี้ & ฉัน & รู้สึก & เมือย & มาก\n",
      "วัน & นี้ & ฉัน & รูสึก & เมือย & มาก\n",
      "วั & นี & ฉั & รู้สึก & เมือย & มา\n",
      "วั & นี & ฉั & รูสึก & เมือย & มา\n"
     ]
    }
   ],
   "source": [
    "for case in cases:\n",
    "    print(\" & \".join(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
