{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/datamind/can/BASIL/notebook\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "mypath = Path().absolute()\n",
    "print(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/datamind/can/BASIL/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/datamind/can/BASIL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datamind/can/BASIL/basil/preprocessing/prep_best_corpus.py:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(ymlfile)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from basil.preprocessing.prep_best_corpus import Best2010NECTEC\n",
    "from basil.preprocessing.prep_pytorch import PytorchPrepWordLevel\n",
    "from basil.models.multitasks.wordlvl_lstm import LSTMTagger\n",
    "from basil.evaluation.stress_test import StressEval\n",
    "from basil.select_device import device\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best2010  = Best2010NECTEC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from basil.evaluation.noise import NoiseGenerator\n",
    "# from basil.preprocessing.prep_pytorch import PytorchPrepWordLevel\n",
    "# prep_torch = PytorchPrepWordLevel(best2010.train_data, best2010.val_data, best2010.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_data  = NoiseGenerator(best2010.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump( noisy_data, open( \"stress_best2010.p\", \"wb\" ) )\n",
    "noisy_data = pickle.load( open( \"stress_best2010.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountFrequency(my_list): \n",
    "      \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for items in my_list: \n",
    "        freq[items] = my_list.count(items) \n",
    "      \n",
    "    for key, value in freq.items(): \n",
    "        print (\"% s : % d\"%(key, value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กับทหาร*ไยท* บริเวณ swap_char\n",
      "ไทย\n",
      "500 *นยา* และ swap_char\n",
      "นาย\n",
      "เจดีย์ขนาด*เลก็* เชิง swap_char\n",
      "เล็ก\n",
      "ของแต่ล*ฝ่ยา*ได้เจรจา swap_char\n",
      "ฝ่าย\n",
      "พฤหัสบดีที่*ต่งา*ฝ่ายต่าง swap_char\n",
      "ต่าง\n",
      "ได้ยิง*กนั*เท่านั้น  swap_char\n",
      "กัน\n",
      " เพียง*แ่ค*เห็นรูปลักษณ์ swap_char\n",
      "แค่\n",
      "เขาเคลื่อนไหว*รวดเรว็*อีกทั้ง swap_char\n",
      "รวดเร็ว\n",
      "ทัสมัย*แะล*มีการ swap_char\n",
      "และ\n",
      " เปอร์เซ็นต์*ขงอ*ทหารที่ swap_char\n",
      "ของ\n",
      "ใช้กอง*ทพั*ในปัจจุบัน swap_char\n",
      "ทัพ\n",
      "ในปัจจุบัน*บรราด*ผู้นำ swap_char\n",
      "บรรดา\n",
      "ต่างสั่งการ*ไ่ม*ให้ทหา swap_char\n",
      "ไม่\n",
      "ขึ้นเมื่อ*สัปดา์ห*ที่แลว้ swap_char\n",
      "สัปดาห์\n",
      "สัปดา์หที่*แลว้* ปราสาท swap_char\n",
      "แล้ว\n",
      "เริ่มขึ้*หลังจกา*ผู้ประท้วง swap_char\n",
      "หลังจาก\n",
      "อยู่ใน*ประเศท*ไทและ swap_char\n",
      "ประเทศ\n",
      "นานผิด*สังเตก* ตาม swap_char\n",
      "สังเกต\n",
      "ตรวจสอบพร้อม*ด้ยว* พ.ต.อ. swap_char\n",
      "ด้วย\n",
      " ผกก.*ส.น*พหลโยธิน  swap_char\n",
      "สน.\n",
      "ชีวิต *คอื* นาย swap_char\n",
      "คือ\n",
      "ลิ่มวิไล *อาุย* 17 swap_char\n",
      "อายุ\n",
      "คือ *นยา*ธีรเดช  swap_char\n",
      "นาย\n",
      "กทม. *เบื้งอ*ต้นแพทย์ swap_char\n",
      "เบื้อง\n",
      "จากการ*สอบสนว*ทรบาว่า swap_char\n",
      "สอบสวน\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "with open('error_survey.csv', mode='w') as error_file:\n",
    "    csv_writer = csv.writer(error_file, delimiter=',')\n",
    "    for data, errors,clean_data in zip(noisy_data.stress10,noisy_data.error10,noisy_data.test_set):\n",
    "        count = 0\n",
    "        for x,err in zip(data, errors):\n",
    "\n",
    "            if err == \"swap_char\" and count >3 and count < len(data)-2   :\n",
    "                perturbed_text = \"\".join([data[count-2][0],data[count-1][0],\"*\",x[0],\"*\",data[count+1][0],data[count+2][0]])\n",
    "                print(perturbed_text,err)\n",
    "                print(clean_data[count][0])\n",
    "                csv_writer.writerow([perturbed_text.replace(\"\\n\", \"\"),clean_data[count][0].replace(\"\\n\", \"\"),err])\n",
    "                err_count +=1\n",
    "            if err_count>=25:\n",
    "                break\n",
    "            count+=1 \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "consonant=\"กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮ\"\n",
    "regex_rule_cons = r\"[\" + consonant +\"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(re.match(regex_rule_cons,\"บ้าน\"[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ทหารเขมร*แด*กระหายจะ last_char\n",
      "แดง\n",
      "กัมพูชาเปิดเผย*ต่*สำนักข่าว last_char\n",
      "ต่อ\n",
      "จะสวม*รองเท้*ฟองน้ำ  last_char\n",
      "รองเท้า\n",
      " 11*แต*บรรยากาศการ last_char\n",
      "แต่\n",
      "สูงของ*แต่ล*ฝ่ยาได้ last_char\n",
      "แต่ละ\n",
      "รับประทานอาหาร*ร่ว*กั  last_char\n",
      "ร่วม\n",
      "อาหารร่ว*กั* ซึ่ง last_char\n",
      "กัน\n",
      "พวกอดีต*ทหา*เขมแดง last_char\n",
      "ทหาร\n",
      "อดีตทหา*เขม*แดง  last_char\n",
      "เขมร\n",
      "เห็นรูปลักษณ์*ภา*นอกของ last_char\n",
      "ภาย\n",
      "ของพวก*เข* ซึ่ง last_char\n",
      "เขา\n",
      "ที่เริ่ม*เป็*ทหารเขมร last_char\n",
      "เป็น\n",
      "พื้นที่ *แล*ยืนยันว่า last_char\n",
      "และ\n",
      "เครื่องแบบที่*ทั*สมัยแะล last_char\n",
      "ทัน\n",
      "ว่า *ทหา*ไทยรู้ last_char\n",
      "ทหาร\n",
      "ทหารเขมร*แด*มาก่อน last_char\n",
      "แดง\n",
      "ไ่มให้*ทหา*เปิดฉากยิง last_char\n",
      "ทหาร\n",
      "ยิง *แล*เรียกร้องให้ last_char\n",
      "และ\n",
      "การเผชิญ*หน้*กันรอบ last_char\n",
      "หน้า\n",
      "พระวิหารเริ่ม*ขึ้*หลังจกาผู้ last_char\n",
      "ขึ้น\n",
      "2505 *ว่* ปราสาท last_char\n",
      "ว่า\n",
      "ในประเศท*ไท*และพื้นที่ last_char\n",
      "ไทย\n",
      "พื้นที่รอบ*ที*ตั้งขนาด last_char\n",
      "ที่\n",
      "เชื่อม *นั*เรียนช่าง last_char\n",
      "นัก\n",
      "เปลี่ยนถัง*ออกซิเจ*ผิดกลาย last_char\n",
      "ออกซิเจน\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "with open('error_survey.csv', mode='a') as error_file:\n",
    "    csv_writer = csv.writer(error_file, delimiter=',')\n",
    "    for data, errors,clean_data in zip(noisy_data.stress10,noisy_data.error10,noisy_data.test_set):\n",
    "        count = 0\n",
    "        for x,err in zip(data, errors):\n",
    "\n",
    "            if err == \"last_char\" and count >3 and count < len(data)-2   :\n",
    "                perturbed_text = \"\".join([data[count-2][0],data[count-1][0],\"*\",x[0],\"*\",data[count+1][0],data[count+2][0]])\n",
    "                print(perturbed_text,err)\n",
    "                print(clean_data[count][0])\n",
    "                csv_writer.writerow([perturbed_text.replace(\"\\n\", \"\"),clean_data[count][0].replace(\"\\n\", \"\"),err])\n",
    "                err_count +=1\n",
    "            if err_count>=25:\n",
    "                break\n",
    "            count+=1 \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ที่เผชิญ*หนา*กับทหาร remove_tone\n",
      "หน้า\n",
      "การเผชิญ*หนา*ค่อนข้างจะ remove_tone\n",
      "หน้า\n",
      "ใบปลิวว่อน*หนา*สภา  remove_tone\n",
      "หน้า\n",
      "งนาร้าน*จำหนาย*วัสดุก่อสร้าง remove_tone\n",
      "จำหน่าย\n",
      "แสดงการ*คัดคาน*ไม่ให้ remove_tone\n",
      "คัดค้าน\n",
      "ตั้งอยู่*ตรงขาม*ฟาร์มไก่ remove_tone\n",
      "ตรงข้าม\n",
      "ร่างสาว*ใหญ*ดับ  remove_tone\n",
      "ใหญ่\n",
      " จุฬาฯ*กลาว*ว่า  remove_tone\n",
      "กล่าว\n",
      " หรอื*จับตอง*ซากสัตว์ remove_tone\n",
      "จับต้อง\n",
      "ปฏิบัติโดย*เครงครัด* ดัง remove_tone\n",
      "เคร่งครัด\n",
      "เฉพาะหลัง*จับตอง*สัตว์ป่วย remove_tone\n",
      "จับต้อง\n",
      "มีใคร*กลา*รับประทานทำ remove_tone\n",
      "กล้า\n",
      "พยาบาลอ.*หาดใหญ*จ.สงขลา remove_tone\n",
      "หาดใหญ่\n",
      "ส่วนที่*เกียวของ*ต่อไป  remove_tone\n",
      "เกี่ยวข้อง\n",
      "ได้ *เจาหนาที*จึงรีบ remove_tone\n",
      "เจ้าหน้าที่\n",
      "โรงพยาบา*กลาว*แะลว่า remove_tone\n",
      "กล่าว\n",
      "เรียบร้อย *อยาง*สื่อที่ remove_tone\n",
      "อย่าง\n",
      " แต่*อยางไรก็ดี*บุคคลทั้ง remove_tone\n",
      "อย่างไรก็ดี\n",
      "ต่อการ*สรางเสริม*สุขภาวะตาม remove_tone\n",
      "สร้างเสริม\n",
      "ราษฎรไ้ด*ปลอย*เลี้ยงไว้ remove_tone\n",
      "ปล่อย\n",
      "อนามยัโลก*เป็นหวง*คือ  remove_tone\n",
      "เป็นห่วง\n",
      "ความไ่ม*ถูกตอง* เพราะ remove_tone\n",
      "ถูกต้อง\n",
      "สำนักงานแพทย์*ใหญ* กรม remove_tone\n",
      "ใหญ่\n",
      "เหยื่ไฟใต้*กวา*ร้อยละ remove_tone\n",
      "กว่า\n",
      " หลัง*เจาหนาที*กัมพูชาจับกุม remove_tone\n",
      "เจ้าหน้าที่\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "with open('error_survey.csv', mode='a') as error_file:\n",
    "    csv_writer = csv.writer(error_file, delimiter=',')\n",
    "    for data, errors,clean_data in zip(noisy_data.stress10,noisy_data.error10,noisy_data.test_set):\n",
    "        count = 0\n",
    "        for x,err in zip(data, errors):\n",
    "\n",
    "            if err == \"remove_tone\" and count >3 and count < len(data)-2   :\n",
    "                perturbed_text = \"\".join([data[count-2][0],data[count-1][0],\"*\",x[0],\"*\",data[count+1][0],data[count+2][0]])\n",
    "                print(perturbed_text,err)\n",
    "                print(clean_data[count][0])\n",
    "                csv_writer.writerow([perturbed_text.replace(\"\\n\", \"\"),clean_data[count][0].replace(\"\\n\", \"\"),err])\n",
    "                err_count +=1\n",
    "            if err_count>=25:\n",
    "                break\n",
    "            count+=1 \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กทม. *ก่ลาว* ทั้งนี้ move_tone\n",
      "กล่าว\n",
      " ส..ว*เชียงให่ม* นาย move_tone\n",
      "เชียงใหม่\n",
      "ชนะเลิศ*ระห่วาง*ทีมฝรั่งเศสกับ move_tone\n",
      "ระหว่าง\n",
      "นอนคว่ำ*ห้นา* อยู่ move_tone\n",
      "หน้า\n",
      "ในการ*รุก้ลำ*ดินแดนและ move_tone\n",
      "รุกล้ำ\n",
      " โรงเรียน*สาย้นำผึ้งในพระอุปถัมภ์*ฯ  move_tone\n",
      "สายน้ำผึ้งในพระอุปถัมภ์\n",
      "ที่ต้อง*เกี่ยว้ของ*กับสัตว์ move_tone\n",
      "เกี่ยวข้อง\n",
      "แล *ข้าวตังห้นาตั้ง* ซึ่ง move_tone\n",
      "ข้าวตังหน้าตั้ง\n",
      "จังหวัดยะลา*ก่ลาว*ว่า  move_tone\n",
      "กล่าว\n",
      "จ.นราธิวาส*ก่ลาว*เห็นด้วยกับ move_tone\n",
      "กล่าว\n",
      "ให้สหกรณ์*จำห่นาย*หนี้ออก move_tone\n",
      "จำหน่าย\n",
      "ก่อนที่*เจ้าห้นาที่*จะออก move_tone\n",
      "เจ้าหน้าที่\n",
      "ออกมา*อ่ยาง*แน่นอนแ่ต move_tone\n",
      "อย่าง\n",
      " จำนว*ก่วา* 100 move_tone\n",
      "กว่า\n",
      "นิวโตฟลิสูง*ก่วา*ปกติเล็กน้อย move_tone\n",
      "กว่า\n",
      "ผูขับ*อ่ยาง*รวดเร็ว  move_tone\n",
      "อย่าง\n",
      "ศาลได้*ก่ลาว*ตักเตือนผู้ move_tone\n",
      "กล่าว\n",
      "เลขาธิการองค์กร*เครือ่ขาย*ภาคประชาชน move_tone\n",
      "เครือข่าย\n",
      "ในบริเวณ*ใก้ลเคียง* ที่ move_tone\n",
      "ใกล้เคียง\n",
      "ไข้หวัด*ให่ญ*เอเวียนฟลูด้วย move_tone\n",
      "ใหญ่\n",
      "สถานการณ์ควา*คืบห้นา*โรคไข้ move_tone\n",
      "คืบหน้า\n",
      "ให้เป็น*ห้นาที่*คณบดีคณะ move_tone\n",
      "หน้าที่\n",
      "เดินทางไป*พ้รอม*กับ  move_tone\n",
      "พร้อม\n",
      "ดูแลครอบครัว*อ่ยาง*เต็มทีขณะ move_tone\n",
      "อย่าง\n",
      "ข้าพเจ้าก็*เศ้ราเสียใจ*มากอยู่แลว้ move_tone\n",
      "เศร้าเสียใจ\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "with open('error_survey.csv', mode='a') as error_file:\n",
    "    csv_writer = csv.writer(error_file, delimiter=',')\n",
    "    for data, errors,clean_data in zip(noisy_data.stress10,noisy_data.error10,noisy_data.test_set):\n",
    "        count = 0\n",
    "        for x,err in zip(data, errors):\n",
    "\n",
    "            if err == \"move_tone\" and count >3 and count < len(data)-2   :\n",
    "                perturbed_text = \"\".join([data[count-2][0],data[count-1][0],\"*\",x[0],\"*\",data[count+1][0],data[count+2][0]])\n",
    "                print(perturbed_text,err)\n",
    "                print(clean_data[count][0])\n",
    "                csv_writer.writerow([perturbed_text.replace(\"\\n\", \"\"),clean_data[count][0].replace(\"\\n\", \"\"),err])\n",
    "                err_count +=1\n",
    "            if err_count>=25:\n",
    "                break\n",
    "            count+=1 \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
